{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd74128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_b4, EfficientNet_B4_Weights\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "weights = EfficientNet_B4_Weights.DEFAULT\n",
    "model = efficientnet_b4(weights=weights)\n",
    "\n",
    "# 이진 분류 - 모델 가져옴\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)#nn.linear(입력텐서, 출력텐서)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16887ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforms 전처리\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((320, 320)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=weights.transforms().mean,\n",
    "                         std=weights.transforms().std)\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((320, 320)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=weights.transforms().mean,\n",
    "                         std=weights.transforms().std)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960d7f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 특징 추출 부분을 고정\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb02cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204cf519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 루프\n",
    "def train_one_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.unsqueeze(1).float().to(device)#BCEWithLogitsLoss는 (N, 1) 형태의 레이블을 기대하므로, unsqueeze로 차원을 추가하고 float로 변환\n",
    "\n",
    "        optimizer.zero_grad()#기울기 초기화 - torch는 기울기 누적시스템\n",
    "\n",
    "        with torch.amp.autocast(\"cuda\"):#자동 혼합 정밀도 사용\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()#기울기 계산\n",
    "        scaler.step(optimizer)#가중치 업데이트\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "503964bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.unsqueeze(1).float().to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061a9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def tta_predict(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    with torch.no_grad():#한개에 이미지에 2가지 예측을 평균내서 최종 예측값\n",
    "        for images in loader:\n",
    "            images = images.to(device)\n",
    "\n",
    "            # 원본\n",
    "            outputs1 = F.sigmoid(model(images))\n",
    "\n",
    "            # 좌우 반전\n",
    "            flipped = torch.flip(images, dims=[3])\n",
    "            outputs2 = F.sigmoid(model(flipped))\n",
    "\n",
    "            # 평균\n",
    "            outputs = (outputs1 + outputs2) / 2\n",
    "            preds.extend(outputs.cpu().numpy())#preds 리스트에 예측값 추가 - cpu로 이동\n",
    "\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f993003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        filename label\n",
      "0   cat.9920.jpg   cat\n",
      "1  cat.11403.jpg   cat\n",
      "2   cat.2180.jpg   cat\n",
      "3   cat.1109.jpg   cat\n",
      "4    dog.696.jpg   dog\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "filenames = os.listdir('train')\n",
    "labels = ['dog' if 'dog' in name else 'cat' for name in filenames]\n",
    "df = pd.DataFrame({'filename' : filenames, 'label' : labels})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "837d933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make custom dataset // 이미지텐서, 라벨텐서로 변환하는 과정\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "class Dataframedataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.dataframe.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = 1 if self.dataframe.iloc[idx, 1] == 'dog' else 0\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5a2bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=df['label']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba0bb647",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataframedataset(\n",
    "    dataframe=train_df,\n",
    "    img_dir='train',\n",
    "    transform=train_transform\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataset = Dataframedataset(\n",
    "    dataframe=val_df,\n",
    "    img_dir='train',\n",
    "    transform=val_transform\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ca5c6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.5688, Val Loss=0.4644\n",
      "Epoch 2: Train Loss=0.3997, Val Loss=0.3367\n",
      "Epoch 3: Train Loss=0.3079, Val Loss=0.2659\n",
      "Epoch 4: Train Loss=0.2515, Val Loss=0.2174\n",
      "Epoch 5: Train Loss=0.2131, Val Loss=0.1854\n",
      "Epoch 6: Train Loss=0.1860, Val Loss=0.1624\n",
      "Epoch 7: Train Loss=0.1665, Val Loss=0.1398\n",
      "Epoch 8: Train Loss=0.1522, Val Loss=0.1284\n",
      "Epoch 9: Train Loss=0.1389, Val Loss=0.1138\n",
      "Epoch 10: Train Loss=0.1289, Val Loss=0.1065\n",
      "Epoch 11: Train Loss=0.1219, Val Loss=0.0976\n",
      "Epoch 12: Train Loss=0.1149, Val Loss=0.0902\n",
      "Epoch 13: Train Loss=0.1080, Val Loss=0.0861\n",
      "Epoch 14: Train Loss=0.1020, Val Loss=0.0825\n",
      "Epoch 15: Train Loss=0.0979, Val Loss=0.0755\n",
      "Epoch 16: Train Loss=0.0954, Val Loss=0.0718\n",
      "Epoch 17: Train Loss=0.0947, Val Loss=0.0706\n",
      "Epoch 18: Train Loss=0.0879, Val Loss=0.0656\n",
      "Epoch 19: Train Loss=0.0873, Val Loss=0.0643\n",
      "Epoch 20: Train Loss=0.0848, Val Loss=0.0623\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    train_loss = train_one_epoch(model, train_loader)\n",
    "    val_loss = validate(model, val_loader)\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e2cc88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.filenames = os.listdir(img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.filenames[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "test_dataset = TestDataset(\n",
    "    img_dir='test',\n",
    "    transform=val_transform\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "592091f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "test_preds = tta_predict(model, test_loader)\n",
    "test_preds = np.array(test_preds).reshape(-1)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test_dataset.filenames,\n",
    "    \"label\": test_preds\n",
    "})\n",
    "\n",
    "submission[\"id\"] = submission[\"id\"].str.replace(\".jpg\", \"\", regex=False)\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b64c404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
